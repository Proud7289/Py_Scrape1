from selenium import webdriver
from selenium.webdriver.firefox.service import Service
from selenium.webdriver.firefox.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd
import time
from datetime import datetime, timedelta

# Path to GeckoDriver
geckodriver_path = r'C:\Users\user\env1\geckodriver.exe'

# Path to Firefox binary
firefox_binary_path = r'C:\Program Files\Mozilla Firefox\firefox.exe'  # Update with your Firefox installation path

# Create Service and Options objects
service = Service(executable_path=geckodriver_path)
options = Options()
options.binary_location = firefox_binary_path

# Define the date range
start_date = datetime.strptime('13-08-2024', '%d-%m-%Y')
end_date = datetime.strptime('20-08-2024', '%d-%m-%Y')

# Initialize an empty DataFrame to store all results
all_data = pd.DataFrame()

# Loop through each date in the range
current_date = start_date
while current_date <= end_date:
    # Format the current date as needed for the URL
    date_str = current_date.strftime('%d-%m-%Y')
    
    # Initialize WebDriver with Service and Options
    driver = webdriver.Firefox(service=service, options=options)

    # Navigate to the webpage with the current date
    url = f'https://archive.twitter-trending.com/united-states/{date_str}'
    driver.get(url)

    # Wait for 5 seconds
    time.sleep(5)

    try:
        # Wait until the elements with class 'word_ars' are present
        WebDriverWait(driver, 10).until(
            EC.presence_of_all_elements_located((By.CLASS_NAME, 'word_ars'))
        )

        # Find all <span> tags with the class 'word_ars' (hashtags)
        span_elements = driver.find_elements(By.CLASS_NAME, 'word_ars')
        hashtags = [span.text for span in span_elements]

        # Find all <span> tags with the class 'table_bbi' (most tweeted)
        most_tweeted_elements = driver.find_elements(By.XPATH, "//span[@class='table_bbi']//span[@class='table_bbk']")
        most_tweeted = [span.text for span in most_tweeted_elements[:5]]  # Get the top 5 most tweeted

        # Find all <span> tags with the class 'table_bbir' (longest trend)
        longest_trend_elements = driver.find_elements(By.XPATH, "//span[@class='table_bbir']//span[@class='table_bbk']")
        longest_trends = [span.text for span in longest_trend_elements[:5]]  # Get the top 5 longest trends

        # Find all <span> tags with the class 'table_bbiv' (tweet counts)
        tweet_count_elements = driver.find_elements(By.CLASS_NAME, 'table_bbiv')
        tweet_counts = [span.text for span in tweet_count_elements[:5]]  # Get the top 5 tweet counts

        # Find all <span> tags with the class 'table_bbivv' (hours)
        trend_hours_elements = driver.find_elements(By.CLASS_NAME, 'table_bbivv')
        trend_hours = [span.text for span in trend_hours_elements[:5]]  # Get the top 5 hours of trends

        # Create a DataFrame for the current date
        df = pd.DataFrame({
            'Date': date_str,
            'Hashtag': hashtags,
            'Most Tweeted': most_tweeted + [''] * (len(hashtags) - len(most_tweeted)),
            'Tweet Count': tweet_counts + [''] * (len(hashtags) - len(tweet_counts)),
            'Longest Trend': longest_trends + [''] * (len(hashtags) - len(longest_trends)),
            'Trend Hours': trend_hours + [''] * (len(hashtags) - len(trend_hours)),
        })

        # Remove duplicate hashtags
        df.drop_duplicates(subset='Hashtag', inplace=True)

        # Append the current day's data to the overall DataFrame
        all_data = pd.concat([all_data, df], ignore_index=True)

    finally:
        # Close the browser
        driver.quit()

    # Move to the next date
    current_date += timedelta(days=1)

# Save the combined DataFrame to a single Excel file
output_path = r'C:\Users\user\env1\archives\us-12-08-to-22-08-2024.xlsx'
all_data.to_excel(output_path, index_label='Index', engine='openpyxl')
